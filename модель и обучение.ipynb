{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Каталог с данными для обучения\n",
    "train_dir = 'train'\n",
    "# Каталог с данными для проверки\n",
    "val_dir = 'val'\n",
    "# Каталог с данными для тестирования\n",
    "test_dir = 'test'\n",
    "# Размеры изображения\n",
    "img_width, img_height = 224, 224\n",
    "# Размерность тензора на основе изображения для входных данных в нейронную сеть\n",
    "# backend Tensorflow, channels_last\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "\n",
    "# Количество эпох\n",
    "epochs = 45\n",
    "# Размер мини-выборки\n",
    "batch_size = 1\n",
    "# Количество изображений для обучения\n",
    "nb_train_samples = 1600\n",
    "# Количество изображений для проверки\n",
    "nb_validation_samples = 800\n",
    "# Количество изображений для тестирования\n",
    "nb_test_samples = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,fill_mode=\"reflect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "1600/1600 [==============================] - 758s - loss: 8.0590 - acc: 0.5000 - val_loss: 7.9583 - val_acc: 0.5062\n",
      "Epoch 2/45\n",
      "1600/1600 [==============================] - 801s - loss: 8.0590 - acc: 0.5000 - val_loss: 8.1396 - val_acc: 0.4950\n",
      "Epoch 3/45\n",
      "1600/1600 [==============================] - 805s - loss: 8.0993 - acc: 0.4975 - val_loss: 7.9382 - val_acc: 0.5075\n",
      "Epoch 4/45\n",
      "1600/1600 [==============================] - 846s - loss: 8.0188 - acc: 0.5025 - val_loss: 8.2202 - val_acc: 0.4900\n",
      "Epoch 5/45\n",
      "   5/1600 [..............................] - ETA: 814s - loss: 9.6709 - acc: 0.4000 "
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Сохраняем сеть\")\n",
    "# Сохраняем сеть для последующего использования\n",
    "# Генерируем описание модели в формате json\n",
    "model_json = model.to_json()\n",
    "json_file = open(\"wow4.json\", \"w\")\n",
    "# Записываем архитектуру сети в файл\n",
    "json_file.write(model_json)\n",
    "json_file.close()\n",
    "# Записываем данные о весах в файл\n",
    "model.save_weights(\"wow4.h5\")\n",
    "print(\"Сохранение сети завершено\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
